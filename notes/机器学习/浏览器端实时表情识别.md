# 浏览器端实时表情识别

## 文档概述

本文档详细说明一款纯前端浏览器端实时表情识别功能的实现代码，该代码基于 `face-api.js` （TensorFlow.js 封装库）开发，无需依赖 Node.js 环境，可直接在现代浏览器中运行，核心实现摄像头调用、人脸检测、7 类基础表情（愤怒、厌恶、恐惧、开心、悲伤、惊讶、中性）实时识别，并增加了 “开心表情” 状态标记功能。

## 一、功能说明

| 核心功能               | 实现细节                                                     |
| ---------------------- | ------------------------------------------------------------ |
| 摄像头权限申请与初始化 | 调用浏览器 `getUserMedia` API 获取摄像头流，支持超时 / 错误处理 |
| 预训练模型加载         | 加载人脸检测、人脸关键点、表情识别三类预训练模型（CDN 托管，无需本地部署） |
| 实时表情识别           | 每 300ms 检测一次视频流中的人脸，输出概率最高的表情及置信度  |
| 开心表情状态标记       | 识别到 “happy” 表情时标记 `happyNow` 为 `true`，其他表情为 `false` |
| 异常处理               | 覆盖摄像头初始化、模型加载、表情检测全流程的错误捕获与提示   |
| 界面优化               | 隐藏视频流展示、美化结果展示区域，适配视频动态尺寸           |

## 二、技术栈依赖

| 技术 / 库             | 作用                                                         |
| --------------------- | ------------------------------------------------------------ |
| HTML5                 | 页面结构搭建，视频流承载（`video` 标签）                     |
| CSS3                  | 页面样式美化、视频隐藏、动画效果（预留）                     |
| JavaScript (ES6+)     | 核心逻辑实现，异步操作、DOM 操作、API 调用                   |
| face-api.js (v1.7.12) | 封装人脸检测 / 关键点 / 表情识别模型，底层基于 TensorFlow.js 浏览器版 |
| CDN 资源              | 加载 `face-api.js` 核心库及预训练模型，无需本地部署          |

## 三、代码结构解析

### 3.1 整体结构

```plaintext
├── HTML 部分：页面结构（视频标签、结果展示区）
├── CSS 部分：样式定义（视频隐藏、结果区美化）
├── JavaScript 部分：
    ├── 状态变量定义（happyNow）
    ├── 开心表情判断函数（happyCheck）
    ├── 摄像头初始化函数（initCamera）
    ├── 模型加载函数（loadModels）
    ├── 实时表情检测函数（detectEmotions）
    ├── 整体初始化流程（init）
    ├── 页面加载触发初始化
```

### 3.2 核心模块详解

#### 3.2.1 HTML 结构

```html
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>浏览器表情识别</title>
  <!-- 引入 face-api.js 核心库（CDN） -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/dist/face-api.min.js"></script>
  <!-- CSS 样式区 -->
  <style>/* 样式定义 */</style>
</head>
<body>
  <!-- 视频流承载标签（隐藏展示） -->
  <video id="video" autoplay muted playsinline></video>
  <!-- 表情识别结果展示区 -->
  <div id="result">加载模型中...</div>
  <!-- JavaScript 核心逻辑 -->
  <script>/* 逻辑代码 */</script>
</body>
</html>
```

#### 3.2.2 CSS 样式

核心样式说明：

- 隐藏视频流：通过 `opacity: 0` + `position: absolute` + `z-index: -1` 隐藏视频标签，但保留摄像头采集功能；
- 结果区美化：设置字体、背景、圆角，提升展示体验；
- 预留动画样式：`photo-animation` 为扩展功能预留闪光灯动画（当前未启用）。

#### 3.2.3 JavaScript 核心逻辑

##### （1）状态变量与开心表情判断

```javascript
// 开心表情状态标记
let happyNow = false;
// 表情判断函数：识别到happy则标记为true，否则为false
const happyCheck = (exp) => {
  happyNow = exp === "happy"; // 简化写法，等价于原逻辑
};
```

##### （2）摄像头初始化（initCamera）

- 核心功能：请求用户摄像头权限，绑定视频流到 `video` 标签；
- 增强处理：增加 5 秒超时保护、视频加载错误捕获，避免无限等待；
- 返回值：Promise 对象，确保视频加载完成后再执行后续逻辑。

##### （3）模型加载（loadModels）

- 加载三类模型：
  - `ssd_mobilenetv1`：轻量级人脸检测模型；
  - `faceLandmark68Net`：68 个人脸关键点模型（用于人脸对齐，提升表情识别准确率）；
  - `faceExpressionNet`：7 类表情识别模型；
- 错误处理：捕获模型加载失败（如网络问题），并给出用户提示。

##### （4）实时表情检测（detectEmotions）

- 检测频率：每 300ms 执行一次（平衡性能与实时性）；
- 尺寸适配：动态获取视频实际尺寸（优先 `videoWidth/videoHeight`，其次 CSS 定义尺寸），避免检测错位；
- 核心逻辑：
  1. 调用 `face-api` 检测视频流中的人脸及表情；
  2. 提取概率最高的表情，展示表情名称及置信度（保留 2 位小数）；
  3. 调用 `happyCheck` 更新开心表情状态；
  4. 无人脸时给出提示，检测出错时捕获异常。

##### （5）整体初始化（init）

执行顺序：初始化摄像头 → 加载模型 → 延迟 1 秒（稳定视频流） → 启动表情检测；异常处理：捕获全流程错误，统一展示错误提示。

##### （6）页面加载触发

```javascript
window.addEventListener('load', init);
```

确保页面所有元素加载完成后再初始化，避免 DOM 操作异常。

## 四、运行方式

### 4.1 环境要求

| 环境 / 浏览器 | 支持情况   | 备注                     |
| ------------- | ---------- | ------------------------ |
| Chrome        | ✅ 完全支持 | 推荐版本 80+             |
| Edge          | ✅ 完全支持 | 基于 Chromium 内核       |
| Firefox       | ✅ 支持     | 需开启摄像头权限         |
| Safari        | ✅ 支持     | 需 macOS 11+/iOS 14+     |
| Node.js       | ❌ 无需     | 纯前端代码，无服务端依赖 |

### 4.2 核心前提：安全上下文

浏览器要求摄像头调用必须在**安全上下文**中运行：

- ❌ 禁止：直接双击打开 HTML 文件（`file://` 协议），会被拒绝摄像头权限；
- ✅ 允许：
  1. 本地调试：`localhost`/`127.0.0.1` 地址（如 Live Server、Python HTTP 服务）；
  2. 线上部署：HTTPS 域名（如 GitHub Pages、Netlify、阿里云 OSS）。

### 4.3 本地运行步骤（推荐）

#### 方式 1：VS Code + Live Server 插件

1. 安装 VS Code 及「Live Server」插件（作者：Ritwick Dey）；
2. 将代码保存为 `index.html`；
3. 右键点击文件 → 选择「Open with Live Server」；
4. 浏览器自动打开 `http://127.0.0.1:5500`，授权摄像头权限即可运行。

#### 方式 2：Python 简易 HTTP 服务

1. 安装 Python（3.x/2.x 均可）；
2. 打开终端，进入代码所在文件夹；
3. 执行命令启动服务：
   - Python 3：`python -m http.server 8080`
   - Python 2：`python -m SimpleHTTPServer 8080`
4. 浏览器访问 `http://localhost:8080`，授权摄像头权限即可运行。

## 五、核心逻辑扩展建议

### 5.1 开心表情触发动作

可基于 `happyNow` 状态扩展功能，例如识别到开心表情时触发截图：

```javascript
// 在 detectEmotions 中增加逻辑
if (happyNow) {
  console.log('检测到开心表情，触发截图');
  // 截图逻辑示例
  const canvas = document.createElement('canvas');
  const video = document.getElementById('video');
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  canvas.getContext('2d').drawImage(video, 0, 0);
  // 生成截图链接
  const imgUrl = canvas.toDataURL('image/png');
  const link = document.createElement('a');
  link.href = imgUrl;
  link.download = 'happy_photo.png';
  link.click();
}
```

### 5.2 性能优化

- 降低检测频率：将 `setInterval` 延迟从 300ms 改为 500ms（移动端建议）；
- 缩小视频尺寸：将摄像头请求的尺寸改为 `{ width: 480, height: 360 }`，减少计算量；
- 模型按需加载：仅加载必要模型，移除无需的人脸关键点（如需简化）。

## 六、常见问题排查

| 问题现象       | 排查方向                                                     |
| -------------- | ------------------------------------------------------------ |
| 摄像头访问失败 | 1. 确认浏览器授予摄像头权限；2. 确认运行在 [localhost/HTTPS](https://localhost/HTTPS) 环境；3. 无其他程序占用摄像头 |
| 模型加载失败   | 1. 检查网络连接；2. 确认 CDN 链接可访问；3. 刷新页面重试     |
| 未检测到人脸   | 1. 确保人脸正对摄像头；2. 环境光线充足；3. 检查视频尺寸是否有效 |
| 识别准确率低   | 1. 确保人脸在视频画面中央；2. 避免侧脸 / 遮挡；3. 更换光线充足环境 |

## 七、总结

该代码是纯前端实现的实时表情识别方案，无需后端 / Node.js 依赖，核心依赖浏览器的 WebAPI 及 `face-api.js` 封装的机器学习模型，适用于前端表情互动、情绪分析等场景。代码内置完善的错误处理和适配逻辑，可直接复用，也可基于 `happyNow` 状态扩展自定义业务逻辑。





# 附件

```html
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>浏览器表情识别</title>
  <!-- 引入 face-api.js 核心库 -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/dist/face-api.min.js"></script>
  <style>
    body { 
      margin: 0; 
      font-family: Arial, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 20px;
    }
    #video { 
      width: 640px; 
      height: 480px;
      border: 2px solid #333;
      border-radius: 8px;
      /* 设置为不可见但保留功能 */
      opacity: 0;
      position: absolute;
      z-index: -1;
    }
    #result { 
      font-size: 20px; 
      margin-top: 15px; 
      color: #333;
      font-weight: bold;
      text-align: center;
      padding: 10px;
      background-color: #f5f5f5;
      border-radius: 5px;
      min-width: 300px;
    }
    #resultImage {
      border: 2px solid #4CAF50;
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .photo-animation {
      animation: flash 0.5s ease-out;
    }
    @keyframes flash {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.3; }
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <div id="result">加载模型中...</div>

  <script>

    let happyNow = false;
    const happyCheck = (exp) => {
      if (exp == "happy") {
        happyNow = true;
      } else {
        happyNow = false;
      }
    }

    // 1. 配置模型路径（使用CDN托管的预训练模型，无需本地部署）
    const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';

    // 2. 初始化摄像头
    async function initCamera() {
      try {
        const video = document.getElementById('video');
        // 请求摄像头权限
        const stream = await navigator.mediaDevices.getUserMedia({ 
          video: { width: 640, height: 480 },
          audio: false 
        });
        
        video.srcObject = stream;
        
        // 确保视频完全加载后再返回
        return new Promise((resolve, reject) => {
          // 设置超时保护
          const timeoutId = setTimeout(() => {
            reject(new Error('视频加载超时'));
          }, 5000);
          
          video.onloadedmetadata = () => {
            clearTimeout(timeoutId);
            console.log('视频已加载，尺寸:', video.videoWidth, 'x', video.videoHeight);
            resolve(video);
          };
          
          video.onerror = (error) => {
            clearTimeout(timeoutId);
            reject(new Error('视频加载错误: ' + error.message));
          };
        });
      } catch (error) {
        console.error('摄像头初始化失败:', error);
        document.getElementById('result').innerText = '摄像头访问失败，请确保已授予权限';
        throw error;
      }
    }

    // 3. 加载表情识别模型（含人脸检测+人脸关键点+表情识别）
    async function loadModels() {
      try {
        // 加载必要的模型：ssd_mobilenetv1（人脸检测）、faceLandmark68（关键点）、faceExpression（表情识别）
        await faceapi.nets.ssdMobilenetv1.load(MODEL_URL);
        await faceapi.nets.faceLandmark68Net.load(MODEL_URL);
        await faceapi.nets.faceExpressionNet.load(MODEL_URL);
        document.getElementById('result').innerText = '模型加载完成，等待视频就绪...';
        return true;
      } catch (error) {
        console.error('模型加载失败:', error);
        document.getElementById('result').innerText = '模型加载失败，请检查网络连接';
        throw error;
      }
    }

    // 4. 实时表情识别
    async function detectEmotions() {
      const video = document.getElementById('video');

      // 循环检测
      setInterval(async () => {
        try {
          // 动态获取video尺寸，优先使用video实际尺寸，其次使用CSS定义的尺寸
          let width = video.videoWidth || video.width || 640;
          let height = video.videoHeight || video.height || 480;
          
          // 确保尺寸有效
          const displaySize = { 
            width: width > 0 ? width : 640, 
            height: height > 0 ? height : 480 
          };
          
          
          // 直接使用video元素进行检测，保持原有功能逻辑
          const detections = await faceapi.detectAllFaces(video)
            .withFaceLandmarks()
            .withFaceExpressions();

          // 只有当检测到有效内容时才进行尺寸调整和绘制
          if (detections && detections.length > 0) {
            // 解析并展示最高概率的表情
            const resultEl = document.getElementById('result');
            const expressions = detections[0].expressions;
            // 找到概率最高的表情
            const topEmotion = Object.entries(expressions)
              .sort((a, b) => b[1] - a[1])[0];
            resultEl.innerText = `当前表情：${topEmotion[0]} (概率：${(topEmotion[1]*100).toFixed(2)}%)`;
            happyCheck(topEmotion[0]);
            console.log(happyNow);
          } else {
            document.getElementById('result').innerText = '未检测到人脸，请对准摄像头';
          }
        } catch (error) {
          console.error('表情识别出错:', error);
          document.getElementById('result').innerText = '识别过程中出现错误';
        }
      }, 300); // 每秒检测一次
    }

    


    // 8. 初始化流程
    async function init() {
      try {
        // 先初始化摄像头，确保视频元素可用
        const video = await initCamera();
        
        // 再加载模型
        await loadModels();
        
        // 等待短暂延迟，确保视频流稳定
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        // 确保视频尺寸有效后再开始识别
        if (video.videoWidth > 0 && video.videoHeight > 0) {
          document.getElementById('result').innerText = '开始识别表情...';
          detectEmotions();
        } else {
          throw new Error('无法获取有效的视频尺寸');
        }
      } catch (error) {
        console.error('初始化失败:', error);
        document.getElementById('result').innerText = '初始化失败: ' + error.message;
      }
    }

    // 启动
    window.addEventListener('load', init); // 确保页面完全加载后再初始化
  </script>
</body>
</html>
```

